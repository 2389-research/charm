{"name": "concurrent-writes-integrity", "description": "Multiple goroutines writing to different keys concurrently", "given": "Empty database with unique temp directory", "when": "10 goroutines each write to their own key simultaneously", "then": "All 10 keys exist with correct values, no corruption", "validates": "Do() handles concurrent writers without data corruption", "runtime_ms": 700}
{"name": "lock-contention-fallback", "description": "DoWithFallback behavior when write lock is held", "given": "Database with one goroutine holding write lock for 500ms", "when": "Another goroutine calls DoWithFallback with WithNoWriteRetry()", "then": "Falls back immediately (or gets write if SQLite WAL allows), can still read data", "validates": "DoWithFallback graceful degradation", "runtime_ms": 1100, "note": "SQLite WAL may allow concurrent writes"}
{"name": "read-write-isolation", "description": "Writers not blocked by active readers", "given": "Database with 5 readers holding connections for 100ms each", "when": "Writer attempts to write while readers are active", "then": "Write completes in <500ms, not blocked by readers", "validates": "SQLite WAL allows writes during reads", "runtime_ms": 700}
{"name": "rapid-cycle-integrity", "description": "Data integrity under rapid open/write/close cycles", "given": "Fresh database, 500 iterations", "when": "Each iteration: Do() writes key, DoReadOnly() verifies immediately", "then": "All 500 keys present and correct at end", "validates": "Do() properly releases resources, no corruption from rapid cycling", "runtime_ms": 260000}
{"name": "starvation-analysis", "description": "Neither readers nor writers starve under contention", "given": "Database with 2 writers and 5 readers running for 3 seconds", "when": "All goroutines continuously perform operations", "then": "Writers complete 10+ ops, readers complete 50+ ops", "validates": "Fair scheduling under contention", "runtime_ms": 3400}
{"name": "wal-recovery", "description": "Data persists across database reopens", "given": "Database with 100 keys written in single Do()", "when": "Database reopened with DoReadOnly()", "then": "All 100 keys present and verified", "validates": "SQLite WAL recovery and data durability", "runtime_ms": 800}
{"name": "transaction-within-do", "description": "Multi-key operations within single Do() are consistent", "given": "Database with 3 related keys (name, age, city)", "when": "10 sequential Do() calls, each updating all 3 keys", "then": "Final state has all 3 keys from same iteration", "validates": "Operations within single Do() are atomic", "runtime_ms": 3600}
{"name": "large-value-handling", "description": "1MB values write and read correctly", "given": "Empty database", "when": "Write 1MB random data, read it back", "then": "Read value equals written value byte-for-byte", "validates": "Large value handling without corruption", "runtime_ms": 800}
{"name": "mixed-operations-stress", "description": "All operation types running concurrently", "given": "Database with 2 Do() writers, 3 DoReadOnly() readers, 2 DoWithFallback() users", "when": "All run for 3 seconds", "then": "100+ total operations, database remains usable", "validates": "System stability under mixed workload", "runtime_ms": 3900}
{"name": "delete-under-contention", "description": "Deletes while reads are happening", "given": "Database seeded with 50 keys, 1 deleter, 3 readers", "when": "All run for 2 seconds", "then": "5+ deletes and 5+ reads complete", "validates": "Deletes don't corrupt during concurrent reads", "runtime_ms": 2600}
{"name": "the-conspiracy", "description": "Everything at once: large values, many writers, deletions, reads", "given": "Database with 2 large writers, 3 small writers, 2 deleters, 4 readers, 2 fallback users", "when": "All run for 5 seconds", "then": "200+ operations, database survives, post-test write succeeds", "validates": "System survives worst-case concurrent stress", "runtime_ms": 6200}
{"name": "write-ordering", "description": "Sequential writes maintain order", "given": "Empty database", "when": "100 sequential Do() calls, each writing increasing number to same key", "then": "Final value is 99 (the last written)", "validates": "Sequential writes are not reordered", "runtime_ms": 31000}
{"name": "sqlite-synchronous-mode", "description": "PRAGMA synchronous=NORMAL is set for durability", "given": "Fresh SQLite database", "when": "Query PRAGMA synchronous", "then": "Returns 1 (NORMAL mode)", "validates": "SQLite durability settings applied", "runtime_ms": 5}
{"name": "sync-lock-acquisition", "description": "Basic sync lock acquire/release", "given": "Empty sync_lock table", "when": "Acquire lock, verify holder, release lock", "then": "Lock acquired, holder matches, lock released", "validates": "Sync lock basic functionality", "runtime_ms": 5}
{"name": "sync-lock-expiry", "description": "Expired locks can be taken over", "given": "Sync lock held with expired timestamp", "when": "New holder attempts to acquire", "then": "New holder takes over the lock", "validates": "Lock expiry prevents deadlocks", "runtime_ms": 5}
{"name": "sync-lock-contention", "description": "Concurrent lock attempts", "given": "Empty sync_lock table", "when": "10 goroutines simultaneously try to acquire lock", "then": "Exactly 1 succeeds, others fail", "validates": "Lock exclusivity under contention", "runtime_ms": 10}
{"name": "pending-ops-recording", "description": "Write operations are tracked durably", "given": "Empty pending_ops table", "when": "Record 3 pending ops (2 sets, 1 delete)", "then": "3 ops in pending_ops table", "validates": "Pending ops are recorded", "runtime_ms": 5}
{"name": "pending-ops-cleared-after-sync", "description": "Pending ops cleared on successful backup", "given": "5 pending ops in table", "when": "Simulate successful sync (clear pending ops)", "then": "0 ops remain in table", "validates": "Pending ops cleanup after sync", "runtime_ms": 5}
{"name": "pending-ops-durability", "description": "Pending ops survive database close/reopen", "given": "10 pending ops written to database", "when": "Close database, reopen", "then": "10 pending ops still present", "validates": "Pending ops survive process restart", "runtime_ms": 10}
{"name": "phase1-schema-tables", "description": "All Phase 1 tables exist in schema", "given": "Fresh database with schema applied", "when": "Query sqlite_master for table names", "then": "kv, meta, sync_lock, pending_ops all exist", "validates": "Schema migration complete", "runtime_ms": 5}
{"name": "doctor-healthy-database", "description": "Doctor reports healthy for clean database", "given": "Fresh database with no issues", "when": "Call Doctor()", "then": "IntegrityOK=true, PendingOpsCount=0, IsHealthy()=true", "validates": "Doctor correctly identifies healthy state", "runtime_ms": 10}
{"name": "doctor-pending-ops-count", "description": "Doctor reports pending ops count", "given": "Database with 5 pending ops", "when": "Call Doctor()", "then": "PendingOpsCount=5, OldestPendingOp is set", "validates": "Doctor counts pending ops", "runtime_ms": 10}
{"name": "doctor-sync-lock-status", "description": "Doctor reports active sync lock", "given": "Database with active sync lock", "when": "Call Doctor()", "then": "SyncLockHeld=true, SyncLockHolder set", "validates": "Doctor detects sync lock", "runtime_ms": 10}
{"name": "doctor-expired-lock-ignored", "description": "Doctor ignores expired sync locks", "given": "Database with expired sync lock", "when": "Call Doctor()", "then": "SyncLockHeld=false", "validates": "Doctor ignores stale locks", "runtime_ms": 10}
{"name": "doctor-old-pending-ops-warning", "description": "Doctor warns about old pending ops", "given": "Database with pending ops older than 24h", "when": "Call Doctor()", "then": "Warning about old pending ops in result", "validates": "Doctor warns about stale pending ops", "runtime_ms": 10}
{"name": "doctor-string-output", "description": "Doctor result has readable string output", "given": "DoctorResult with various states", "when": "Call String()", "then": "Human-readable output with checkmarks and warnings", "validates": "Doctor result is user-friendly", "runtime_ms": 5}
{"name": "content-hash-deterministic", "description": "Same content produces same hash", "given": "Fixed byte array", "when": "Call contentHash() twice", "then": "Both calls return identical 32-char hex string", "validates": "Content addressing is deterministic", "runtime_ms": 5}
{"name": "manifest-add-backup-idempotent", "description": "Adding same backup twice is a no-op", "given": "Manifest with one backup (seq=1, hash=abc)", "when": "Add same backup entry again", "then": "Manifest still has exactly 1 backup", "validates": "Manifest AddBackup is idempotent", "runtime_ms": 5}
{"name": "manifest-sorted-descending", "description": "Backups sorted newest first", "given": "Empty manifest", "when": "Add backups with seq 3, 1, 5 in that order", "then": "Backups slice is [5, 3, 1]", "validates": "Manifest maintains sorted order", "runtime_ms": 5}
{"name": "manifest-latest-backup", "description": "LatestBackup returns highest seq", "given": "Manifest with seq 1, 5, 3", "when": "Call LatestBackup()", "then": "Returns backup with seq=5", "validates": "LatestBackup finds correct entry", "runtime_ms": 5}
{"name": "manifest-backups-after", "description": "BackupsAfter filters correctly", "given": "Manifest with seq 1, 3, 5, 7", "when": "Call BackupsAfter(3)", "then": "Returns backups with seq 5, 7 only", "validates": "BackupsAfter filters by sequence", "runtime_ms": 5}
{"name": "manifest-json-roundtrip", "description": "Manifest survives JSON serialization", "given": "Manifest with version, seq, backups, device ID", "when": "MarshalJSON then UnmarshalManifest", "then": "All fields preserved exactly", "validates": "Manifest JSON serialization", "runtime_ms": 5}
{"name": "manifest-version-validation", "description": "Future manifest versions rejected", "given": "JSON with version=999", "when": "UnmarshalManifest()", "then": "Returns error about unsupported version", "validates": "Manifest version compatibility", "runtime_ms": 5}
{"name": "backup-entry-storage-key", "description": "BackupEntry generates correct key", "given": "BackupEntry with seq=42, hash=abc123", "when": "Call StorageKey(\"mydb\")", "then": "Returns \"mydb/42-abc123\"", "validates": "Content-addressed backup key format", "runtime_ms": 5}
{"name": "hlc-monotonic", "description": "HLC timestamps always increase", "given": "Fresh HLC instance", "when": "Call Now() 1000 times rapidly", "then": "Each timestamp > previous", "validates": "HLC monotonicity guarantee", "runtime_ms": 5}
{"name": "hlc-concurrent-unique", "description": "Concurrent HLC calls produce unique values", "given": "10 goroutines, each calling Now() 10 times", "when": "All execute simultaneously", "then": "All 100 timestamps are unique", "validates": "HLC thread safety", "runtime_ms": 10}
{"name": "hlc-update-forward", "description": "HLC.Update advances past received time", "given": "HLC with current time", "when": "Update with future timestamp", "then": "Result > received timestamp", "validates": "HLC handles clock skew", "runtime_ms": 5}
{"name": "op-log-idempotent", "description": "Applying same op twice is no-op", "given": "Op with unique op_id applied once", "when": "Apply same op again", "then": "Second apply returns false, value unchanged", "validates": "Op-log idempotency", "runtime_ms": 5}
{"name": "op-log-conflict-resolution", "description": "Newer HLC timestamp wins", "given": "Key with op at HLC=2000", "when": "Apply op for same key with HLC=1000", "then": "Op logged but value unchanged (newer wins)", "validates": "Last-write-wins by HLC", "runtime_ms": 5}
{"name": "op-log-unsynced-tracking", "description": "Unsynced ops tracked correctly", "given": "5 ops inserted, 3 marked synced", "when": "Call getUnsyncedOps()", "then": "Returns exactly 2 unsynced ops in order", "validates": "Sync status tracking", "runtime_ms": 5}
{"name": "op-log-seq-generation", "description": "Sequence numbers auto-increment", "given": "Empty op_log table", "when": "getNextSeq(), insert op, getNextSeq()", "then": "Returns 1, then 2", "validates": "Sequence generation", "runtime_ms": 5}
{"name": "op-log-delete-applies", "description": "Delete ops remove keys", "given": "Key with value set", "when": "Apply delete op", "then": "Key returns ErrMissingKey", "validates": "Delete operation handling", "runtime_ms": 5}
